{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2019 Semester 1\n",
    "-----\n",
    "## Project 1: Gaining Information about Naive Bayes\n",
    "-----\n",
    "###### Student Name(s):  Li Shangqian    908462\n",
    "###### Python version: Python 3\n",
    "###### Submission deadline: 1pm, Fri 5 Apr 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you may use for your Project 1 submission. (You are not required to use it; in particular, there is no need to use iPython if you do not like it.)\n",
    "\n",
    "Marking will be applied on the five functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def preprocess(file):\n",
    "    \n",
    "    \n",
    "    raw=csv.reader(open(file))\n",
    "    \n",
    "    \n",
    "    data=list(raw)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should build a supervised NB model\n",
    "\n",
    "#find prior probability for each class\n",
    "def get_prior(data):\n",
    "    \n",
    "    pri_count={}\n",
    "    \n",
    "    \n",
    "    #count number of the classes\n",
    "    for instance in data:\n",
    "        class_label=instance[-1]\n",
    "        if class_label not in pri_count:\n",
    "            pri_count[class_label]=1\n",
    "        else:\n",
    "            pri_count[class_label]+=1\n",
    "    \n",
    "    #divide the number by the sum to get the prior probability\n",
    "    for key, value in pri_count.items():\n",
    "        pri_count[key]=value/len(data)\n",
    "        \n",
    "    \n",
    "    return pri_count\n",
    "\n",
    "\n",
    "\n",
    "#find posterior probaility for the data\n",
    "#parameter: \n",
    "#pri_count--- the prior probability for the dataset \n",
    "def get_posterior(data, pri_count):\n",
    "\n",
    "       \n",
    "    post_count={}\n",
    "            \n",
    "    attribute_types=[]\n",
    "    \n",
    "    \n",
    "    #since lapalce smoothing is used in this project, \n",
    "    #first we record all the possible values for each attribute except for missing value\n",
    "    for attribute in range(len(data[0])-1):\n",
    "        attr={}\n",
    "        for instance in data:\n",
    "            if instance[attribute]!=\"?\":\n",
    "                if instance[attribute] not in attr:\n",
    "                    attr[instance[attribute]]=0\n",
    "        attribute_types.append(attr)\n",
    "\n",
    "    \n",
    "    for attribute in range(len(data[0])-1):\n",
    "        \n",
    "        attribute_post={}\n",
    "        diverse=len(attribute_types[attribute])\n",
    "        \n",
    "        #for each class and each attribute, record the posteriror count\n",
    "        for classes in pri_count.keys():\n",
    "            attribute_post[classes]={}\n",
    "            for key,value in attribute_types[attribute].items():\n",
    "                attribute_post[classes][key]=value\n",
    "                \n",
    "        for instance in data:\n",
    "            if instance[attribute] !=\"?\":\n",
    "                if instance[attribute] in attribute_post[instance[-1]]:\n",
    "                    attribute_post[instance[-1]][instance[attribute]]+=1\n",
    "           \n",
    "        #use add-1 smoothing\n",
    "        for classes in pri_count.keys():\n",
    "            sums=sum(attribute_post[classes].values())\n",
    "            for key, value in attribute_post[classes].items():\n",
    "                attribute_post[classes][key]=(1+value)/(diverse+sums)\n",
    "        \n",
    "        post_count[attribute]=attribute_post\n",
    "    \n",
    "    return post_count\n",
    "    \n",
    "    \n",
    "    \n",
    "def train(data):\n",
    "    \n",
    "    prior=get_prior(data)\n",
    "    \n",
    "    posterior=get_posterior(data,prior)\n",
    "    \n",
    "    return prior, posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a posterior probaility function that has no smoothing \n",
    "def get_post2(data, pri_count):\n",
    "\n",
    "       \n",
    "    post_count={}\n",
    "            \n",
    "    attribute_types=[]\n",
    "    \n",
    "    \n",
    "    #since lapalce smoothing is used in this project, \n",
    "    #first we record all the possible values for each attribute except for missing value\n",
    "    for attribute in range(len(data[0])-1):\n",
    "        attr={}\n",
    "        for instance in data:\n",
    "            if instance[attribute]!=\"?\":\n",
    "                if instance[attribute] not in attr:\n",
    "                    attr[instance[attribute]]=0\n",
    "        attribute_types.append(attr)\n",
    "\n",
    "    \n",
    "    for attribute in range(len(data[0])-1):\n",
    "        \n",
    "        attribute_post={}\n",
    "        diverse=len(attribute_types[attribute])\n",
    "        \n",
    "        #for each class and each attribute, record the posteriror count\n",
    "        for classes in pri_count.keys():\n",
    "            attribute_post[classes]={}\n",
    "            for key,value in attribute_types[attribute].items():\n",
    "                attribute_post[classes][key]=value\n",
    "                \n",
    "        for instance in data:\n",
    "            if instance[attribute] !=\"?\":\n",
    "                if instance[attribute] in attribute_post[instance[-1]]:\n",
    "                    attribute_post[instance[-1]][instance[attribute]]+=1\n",
    "           \n",
    "        #use no smoothing\n",
    "        for classes in pri_count.keys():\n",
    "            sums=sum(attribute_post[classes].values())\n",
    "            if sums!=0:\n",
    "                for key, value in attribute_post[classes].items():\n",
    "                    attribute_post[classes][key]=value/sums\n",
    "        \n",
    "        post_count[attribute]=attribute_post\n",
    "    \n",
    "    return post_count\n",
    "\n",
    "#train data without lapace smoothing\n",
    "def train2(data):\n",
    "    \n",
    "    prior=get_prior(data)\n",
    "    \n",
    "    posterior=get_post2(data,prior)\n",
    "    \n",
    "    return prior, posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class for an instance or a set of instances, based on a trained model \n",
    "def predict(data, prior, post):\n",
    "    \n",
    "    #list to store the predictions\n",
    "    prediction=[]\n",
    "    \n",
    "    #loop through the data to calculate the prediction probaility\n",
    "    for instance in data:\n",
    "        calculation_dict=get_standard(prior)\n",
    "        for key, value in calculation_dict.items():\n",
    "            for i in range(len(instance)-1):\n",
    "                attribute=instance[i]\n",
    "                if attribute in post[i][key]:\n",
    "                    calculation_dict[key]*=post[i][key][attribute]\n",
    "        #record the maximum and accept it as the predcition result\n",
    "        prediction.append(max(calculation_dict, key=calculation_dict.get))\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "#function produce a standard vector recording prior probaility for caluculation\n",
    "#the reason to produce a new vector but not use the raw one is to prevent any potential memory leaks\n",
    "def get_standard(prior):\n",
    "    pri_dict={}\n",
    "    for key, value in prior.items():\n",
    "        pri_dict[key]=value\n",
    "    \n",
    "    return pri_dict\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate(data, prediction):\n",
    "    \n",
    "    print(\"The accracy is \",get_accuracy(data, prediction)/len(data))\n",
    "    \n",
    "    \n",
    "    matrix=confusion(data, prediction)\n",
    "      \n",
    "    print('\\n')\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print('\\n')\n",
    "    print_confusion(matrix)\n",
    "    \n",
    "    print('\\n')\n",
    "    recall(matrix)\n",
    "    print('\\n')\n",
    "    precision(matrix)\n",
    "    print('\\n')\n",
    "    return\n",
    "\n",
    "def get_accuracy(data, prediction):\n",
    "    \n",
    "    count=0\n",
    "    #count the num of accurate prediction\n",
    "    for i in range(len(data)):\n",
    "        if data[i][-1]==prediction[i]:\n",
    "            count+=1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def confusion(data, prediction):\n",
    "    \n",
    "    matrix_data={}\n",
    "    actual_labels=[]\n",
    "    accurates=get_accuracy(data,prediction)\n",
    "    #find the distinct classes that exist\n",
    "    for i in range(len(data)):\n",
    "        actual_labels.append(data[i][-1])\n",
    "    #make a dict for each class\n",
    "    for instance in data:\n",
    "        matrix_data[instance[-1]]={}\n",
    "    #match the numbers for each actual classes based on the predictions, the result is the confusion matrix\n",
    "    for key in matrix_data.keys():\n",
    "        for instance in data:\n",
    "            matrix_data[key][instance[-1]]=0\n",
    "    \n",
    "    for j in range(len(prediction)):\n",
    "        matrix_data[actual_labels[j]][prediction[j]]+=1\n",
    "        \n",
    "    return matrix_data\n",
    "\n",
    "\n",
    "#print the matrix\n",
    "def print_confusion(matrix_data):\n",
    "    \n",
    "    print('|Actual\\Predict|',end='')\n",
    "    for k, v in matrix_data.items():\n",
    "        print('{0:^20s}'.format(k),end='')\n",
    "    print()\n",
    "    for k, v in matrix_data.items():\n",
    "        print('{0:^20s}'.format(k),end='')\n",
    "        for values in v.values():\n",
    "            print('{0:^20d}'.format(values),end='')\n",
    "        print()\n",
    "    return\n",
    "\n",
    "#function to find recalls\n",
    "def recall(matrix):\n",
    "    \n",
    "    recalls={}\n",
    "    for k, v in matrix.items():\n",
    "        tp=matrix[k][k]\n",
    "        fn=sum(v.values())\n",
    "        if fn==0:\n",
    "            recalls[k]=0\n",
    "        else:\n",
    "            recalls[k]=tp/fn\n",
    "        \n",
    "    for k,v in recalls.items():\n",
    "        print(\"Class        \", k, \"          's  recall is         \",v)\n",
    "    \n",
    "    \n",
    "    print(\"The micro-average recall is               \",sum(recalls.values())/len(matrix))\n",
    "    return\n",
    "\n",
    "    #function to find precision\n",
    "def precision(matrix):\n",
    "    \n",
    "    precisions={}\n",
    "    for k, v in matrix.items():\n",
    "        tp=matrix[k][k]\n",
    "        fp=0\n",
    "        for key, value in matrix.items():\n",
    "            fp+=matrix[key][k]\n",
    "        if fp==0:\n",
    "            precisions[k]=0\n",
    "        else:\n",
    "            precisions[k]=tp/fp\n",
    "        \n",
    "    for k,v in precisions.items():\n",
    "        print(\"Class        \", k, \"          's  precision is         \",v)\n",
    "    \n",
    "    print(\"The micro-average precision is               \",sum(precisions.values())/len(matrix))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculate the Information Gain of an attribute or a set of attribute, with respect to the class\n",
    "def info_gain(data, prediction):\n",
    "    \n",
    "    \n",
    "    entropy_data=[]\n",
    "    \n",
    "    mean_info=[]\n",
    "    \n",
    "    prior,post=train(data)\n",
    "    \n",
    "    #first calculate the number and appearance of each attribute branching\n",
    "    for attribute in range(len(data[0])-1):\n",
    "        attr_data={}\n",
    "        for instance in data:\n",
    "            if instance[attribute]!=\"?\":\n",
    "                if instance[attribute] not in attr_data:\n",
    "                    attr_data[instance[attribute]]={}\n",
    "            if instance[attribute]!=\"?\":\n",
    "                if instance[-1] not in attr_data[instance[attribute]]:\n",
    "                    attr_data[instance[attribute]][instance[-1]]=1\n",
    "                else:\n",
    "                    attr_data[instance[attribute]][instance[-1]]+=1\n",
    "        \n",
    "        entropy_data.append(attr_data)\n",
    "    \n",
    "    #calculate the entropy for each attribute branching, sum of each attr_H is the mean_infor of an attribute\n",
    "    for i in range(len(entropy_data)):\n",
    "        attr_H={}\n",
    "        for key, value in entropy_data[i].items():\n",
    "            entropy=0\n",
    "            the_sum=sum(value.values())\n",
    "            for v in value.values():\n",
    "                entropy+=(v/the_sum)*math.log(v/the_sum,2)\n",
    "            attr_H[key]=-entropy*(the_sum/len(data))\n",
    "        mean_info.append(attr_H)\n",
    "    \n",
    "    H_R=0\n",
    "    \n",
    "    #get the entropy for parents\n",
    "    for key,value in prior.items():\n",
    "        H_R+=value*(math.log(value,2))\n",
    "        \n",
    "    H_R=H_R*(-1)\n",
    "    \n",
    "    \n",
    "    #get the information gain for each attribute\n",
    "    for i in range(len(mean_info)):\n",
    "        mi=0\n",
    "        for key,value in mean_info[i].items():\n",
    "            mi+=value\n",
    "        print(\"The information gain for attribute     \", i, \"       is       \", H_R-mi)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the dataset is anneal.csv\n",
      "The accracy is  0.9910913140311804\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|         3                   U                   1                   5                   2          \n",
      "         3                  677                  2                   0                   0                   5          \n",
      "         U                   0                   40                  0                   0                   0          \n",
      "         1                   0                   0                   8                   0                   0          \n",
      "         5                   0                   0                   0                   67                  0          \n",
      "         2                   1                   0                   0                   0                   98         \n",
      "\n",
      "\n",
      "Class         3           's  recall is          0.9897660818713451\n",
      "Class         U           's  recall is          1.0\n",
      "Class         1           's  recall is          1.0\n",
      "Class         5           's  recall is          1.0\n",
      "Class         2           's  recall is          0.98989898989899\n",
      "The micro-average recall is                0.995933014354067\n",
      "\n",
      "\n",
      "Class         3           's  precision is          0.9985250737463127\n",
      "Class         U           's  precision is          0.9523809523809523\n",
      "Class         1           's  precision is          1.0\n",
      "Class         5           's  precision is          1.0\n",
      "Class         2           's  precision is          0.9514563106796117\n",
      "The micro-average precision is                0.9804724673613754\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.40908953764451006\n",
      "The information gain for attribute      1        is        0.0\n",
      "The information gain for attribute      2        is        0.3060515354289405\n",
      "The information gain for attribute      3        is        0.051344088764404106\n",
      "The information gain for attribute      4        is        0.29108220585994726\n",
      "The information gain for attribute      5        is        0.14711886228095605\n",
      "The information gain for attribute      6        is        0.2137228803159088\n",
      "The information gain for attribute      7        is        0.29223544065798446\n",
      "The information gain for attribute      8        is        0.1261663361036096\n",
      "The information gain for attribute      9        is        0.14107379163812883\n",
      "The information gain for attribute      10        is        0.032488406491841815\n",
      "The information gain for attribute      11        is        0.43517783626288575\n",
      "The information gain for attribute      12        is        0.03870173274881061\n",
      "The information gain for attribute      13        is        0.00043760652021185287\n",
      "The information gain for attribute      14        is        0.03935557414283708\n",
      "The information gain for attribute      15        is        0.021775078259213876\n",
      "The information gain for attribute      16        is        0.037997478813511565\n",
      "The information gain for attribute      17        is        0.03670308136440825\n",
      "The information gain for attribute      18        is        0.0\n",
      "The information gain for attribute      19        is        0.11722522630372034\n",
      "The information gain for attribute      20        is        0.029753745208638938\n",
      "The information gain for attribute      21        is        0.02704235332867677\n",
      "The information gain for attribute      22        is        0.0\n",
      "The information gain for attribute      23        is        0.015604780443500665\n",
      "The information gain for attribute      24        is        0.13718113252042574\n",
      "The information gain for attribute      25        is        0.0\n",
      "The information gain for attribute      26        is        0.0223970898516459\n",
      "The information gain for attribute      27        is        0.01824168402125048\n",
      "The information gain for attribute      28        is        0.0\n",
      "The information gain for attribute      29        is        0.0\n",
      "The information gain for attribute      30        is        0.0\n",
      "The information gain for attribute      31        is        0.04323960556514961\n",
      "The information gain for attribute      32        is        0.03303757117705719\n",
      "The information gain for attribute      33        is        0.01937886432831948\n",
      "The information gain for attribute      34        is        0.003958783545891853\n",
      "distribution of the classes are\n",
      "{'3': 0.7616926503340757, 'U': 0.044543429844097995, '1': 0.008908685968819599, '5': 0.07461024498886415, '2': 0.11024498886414254}\n",
      "\n",
      "\n",
      "number of the attributes are       35\n",
      "\n",
      "\n",
      "number of the instances are       898\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is breast-cancer.csv\n",
      "The accracy is  0.7587412587412588\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict| recurrence-events  no-recurrence-events\n",
      " recurrence-events           47                  38         \n",
      "no-recurrence-events         31                 170         \n",
      "\n",
      "\n",
      "Class         recurrence-events           's  recall is          0.5529411764705883\n",
      "Class         no-recurrence-events           's  recall is          0.845771144278607\n",
      "The micro-average recall is                0.6993561603745977\n",
      "\n",
      "\n",
      "Class         recurrence-events           's  precision is          0.6025641025641025\n",
      "Class         no-recurrence-events           's  precision is          0.8173076923076923\n",
      "The micro-average precision is                0.7099358974358974\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.010605956535614136\n",
      "The information gain for attribute      1        is        0.0020016149737116518\n",
      "The information gain for attribute      2        is        0.05717112532429669\n",
      "The information gain for attribute      3        is        0.06899508808988597\n",
      "The information gain for attribute      4        is        0.08012009687900967\n",
      "The information gain for attribute      5        is        0.07700985251661441\n",
      "The information gain for attribute      6        is        0.0024889884332655043\n",
      "The information gain for attribute      7        is        0.015066622054149992\n",
      "The information gain for attribute      8        is        0.025819023909141148\n",
      "distribution of the classes are\n",
      "{'recurrence-events': 0.2972027972027972, 'no-recurrence-events': 0.7027972027972028}\n",
      "\n",
      "\n",
      "number of the attributes are       9\n",
      "\n",
      "\n",
      "number of the instances are       286\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is car.csv\n",
      "The accracy is  0.8738425925925926\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|       unacc                acc                vgood                good        \n",
      "       unacc                1161                 47                  0                   2          \n",
      "        acc                  85                 289                  0                   10         \n",
      "       vgood                 0                   26                  39                  0          \n",
      "        good                 0                   46                  2                   21         \n",
      "\n",
      "\n",
      "Class         unacc           's  recall is          0.959504132231405\n",
      "Class         acc           's  recall is          0.7526041666666666\n",
      "Class         vgood           's  recall is          0.6\n",
      "Class         good           's  recall is          0.30434782608695654\n",
      "The micro-average recall is                0.654114031246257\n",
      "\n",
      "\n",
      "Class         unacc           's  precision is          0.9317817014446228\n",
      "Class         acc           's  precision is          0.7083333333333334\n",
      "Class         vgood           's  precision is          0.9512195121951219\n",
      "Class         good           's  precision is          0.6363636363636364\n",
      "The micro-average precision is                0.8069245458341786\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.09644896916961399\n",
      "The information gain for attribute      1        is        0.07370394692148596\n",
      "The information gain for attribute      2        is        0.004485716626632108\n",
      "The information gain for attribute      3        is        0.2196629633399082\n",
      "The information gain for attribute      4        is        0.030008141247605424\n",
      "The information gain for attribute      5        is        0.26218435655426386\n",
      "distribution of the classes are\n",
      "{'unacc': 0.7002314814814815, 'acc': 0.2222222222222222, 'vgood': 0.03761574074074074, 'good': 0.03993055555555555}\n",
      "\n",
      "\n",
      "number of the attributes are       6\n",
      "\n",
      "\n",
      "number of the instances are       1728\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is cmc.csv\n",
      "The accracy is  0.5057705363204344\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|       No-use            Long-term           Short-term     \n",
      "       No-use               373                 135                 121         \n",
      "     Long-term               62                 191                  80         \n",
      "     Short-term             173                 157                 181         \n",
      "\n",
      "\n",
      "Class         No-use           's  recall is          0.5930047694753577\n",
      "Class         Long-term           's  recall is          0.5735735735735735\n",
      "Class         Short-term           's  recall is          0.3542074363992172\n",
      "The micro-average recall is                0.5069285931493829\n",
      "\n",
      "\n",
      "Class         No-use           's  precision is          0.6134868421052632\n",
      "Class         Long-term           's  precision is          0.39544513457556935\n",
      "Class         Short-term           's  precision is          0.4738219895287958\n",
      "The micro-average precision is                0.4942513220698761\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.07090633894894594\n",
      "The information gain for attribute      1        is        0.04013859922938412\n",
      "The information gain for attribute      2        is        0.10173991727554088\n",
      "The information gain for attribute      3        is        0.009820501434384843\n",
      "The information gain for attribute      4        is        0.002582332379721608\n",
      "The information gain for attribute      5        is        0.030474214560266555\n",
      "The information gain for attribute      6        is        0.032511460053806784\n",
      "The information gain for attribute      7        is        0.015786455595620197\n",
      "distribution of the classes are\n",
      "{'No-use': 0.4270196877121521, 'Long-term': 0.22606924643584522, 'Short-term': 0.3469110658520027}\n",
      "\n",
      "\n",
      "number of the attributes are       8\n",
      "\n",
      "\n",
      "number of the instances are       1473\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is hepatitis.csv\n",
      "The accracy is  0.8387096774193549\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|        LIVE                DIE         \n",
      "        LIVE                107                  16         \n",
      "        DIE                  9                   23         \n",
      "\n",
      "\n",
      "Class         LIVE           's  recall is          0.8699186991869918\n",
      "Class         DIE           's  recall is          0.71875\n",
      "The micro-average recall is                0.7943343495934959\n",
      "\n",
      "\n",
      "Class         LIVE           's  precision is          0.9224137931034483\n",
      "Class         DIE           's  precision is          0.5897435897435898\n",
      "The micro-average precision is                0.756078691423519\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.03660746514280977\n",
      "The information gain for attribute      1        is        0.015265380561918285\n",
      "The information gain for attribute      2        is        0.014490701150154384\n",
      "The information gain for attribute      3        is        0.08645063847884216\n",
      "The information gain for attribute      4        is        0.08322845589007444\n",
      "The information gain for attribute      5        is        0.013806029835453981\n",
      "The information gain for attribute      6        is        0.0903522944652434\n",
      "The information gain for attribute      7        is        0.09049078626122975\n",
      "The information gain for attribute      8        is        0.058739302370822144\n",
      "The information gain for attribute      9        is        0.12938741279822152\n",
      "The information gain for attribute      10        is        0.15163520023638288\n",
      "The information gain for attribute      11        is        0.10012174391687245\n",
      "The information gain for attribute      12        is        0.08493296456638777\n",
      "distribution of the classes are\n",
      "{'LIVE': 0.7935483870967742, 'DIE': 0.2064516129032258}\n",
      "\n",
      "\n",
      "number of the attributes are       13\n",
      "\n",
      "\n",
      "number of the instances are       155\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the dataset is hypothyroid.csv\n",
      "The accracy is  0.9522605121719886\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|    hypothyroid           negative      \n",
      "    hypothyroid              0                  151         \n",
      "      negative               0                  3012        \n",
      "\n",
      "\n",
      "Class         hypothyroid           's  recall is          0.0\n",
      "Class         negative           's  recall is          1.0\n",
      "The micro-average recall is                0.5\n",
      "\n",
      "\n",
      "Class         hypothyroid           's  precision is          0\n",
      "Class         negative           's  precision is          0.9522605121719886\n",
      "The micro-average precision is                0.4761302560859943\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.004628873031652547\n",
      "The information gain for attribute      1        is        0.0009139351160850073\n",
      "The information gain for attribute      2        is        0.0012382074503017315\n",
      "The information gain for attribute      3        is        0.00014844815831743796\n",
      "The information gain for attribute      4        is        0.0009985293906336068\n",
      "The information gain for attribute      5        is        0.0013683791752741592\n",
      "The information gain for attribute      6        is        0.0005423006444424394\n",
      "The information gain for attribute      7        is        0.0004350938464638965\n",
      "The information gain for attribute      8        is        0.0004888757691284829\n",
      "The information gain for attribute      9        is        0.0008983004044028076\n",
      "The information gain for attribute      10        is        4.463778824304043e-05\n",
      "The information gain for attribute      11        is        7.8684698479492e-05\n",
      "The information gain for attribute      12        is        0.009353710215580346\n",
      "The information gain for attribute      13        is        0.004075493419623766\n",
      "The information gain for attribute      14        is        0.005792553705846859\n",
      "The information gain for attribute      15        is        0.005768288201614624\n",
      "The information gain for attribute      16        is        0.005744031245602799\n",
      "The information gain for attribute      17        is        0.002580427555574416\n",
      "distribution of the classes are\n",
      "{'hypothyroid': 0.04773948782801138, 'negative': 0.9522605121719886}\n",
      "\n",
      "\n",
      "number of the attributes are       18\n",
      "\n",
      "\n",
      "number of the instances are       3163\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is mushroom.csv\n",
      "The accracy is  0.9958148695224027\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|         p                   e          \n",
      "         p                  3913                 3          \n",
      "         e                   31                 4177        \n",
      "\n",
      "\n",
      "Class         p           's  recall is          0.9992339121552605\n",
      "Class         e           's  recall is          0.9926330798479087\n",
      "The micro-average recall is                0.9959334960015847\n",
      "\n",
      "\n",
      "Class         p           's  precision is          0.9921399594320487\n",
      "Class         e           's  precision is          0.9992822966507177\n",
      "The micro-average precision is                0.9957111280413832\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.04879670193537311\n",
      "The information gain for attribute      1        is        0.028590232773772817\n",
      "The information gain for attribute      2        is        0.03604928297620391\n",
      "The information gain for attribute      3        is        0.19237948576121966\n",
      "The information gain for attribute      4        is        0.9060749773839998\n",
      "The information gain for attribute      5        is        0.014165027250616302\n",
      "The information gain for attribute      6        is        0.10088318399657026\n",
      "The information gain for attribute      7        is        0.23015437514804615\n",
      "The information gain for attribute      8        is        0.41697752341613137\n",
      "The information gain for attribute      9        is        0.007516772569664321\n",
      "The information gain for attribute      10        is        0.4001378247172982\n",
      "The information gain for attribute      11        is        0.2847255992184845\n",
      "The information gain for attribute      12        is        0.2718944733927464\n",
      "The information gain for attribute      13        is        0.2538451734622399\n",
      "The information gain for attribute      14        is        0.24141556652756657\n",
      "The information gain for attribute      15        is        0.0\n",
      "The information gain for attribute      16        is        0.0238170161209168\n",
      "The information gain for attribute      17        is        0.03845266924309054\n",
      "The information gain for attribute      18        is        0.3180215107935376\n",
      "The information gain for attribute      19        is        0.4807049176849154\n",
      "The information gain for attribute      20        is        0.2019580190668524\n",
      "The information gain for attribute      21        is        0.1568336046050921\n",
      "distribution of the classes are\n",
      "{'p': 0.48202855736090594, 'e': 0.517971442639094}\n",
      "\n",
      "\n",
      "number of the attributes are       22\n",
      "\n",
      "\n",
      "number of the instances are       8124\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is nursery.csv\n",
      "The accracy is  0.9030864197530865\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|     recommend            priority           not_recom           very_recom          spec_prior     \n",
      "     recommend               0                   0                   0                   2                   0          \n",
      "      priority               0                  3852                 0                   0                  414         \n",
      "     not_recom               0                   0                  4320                 0                   0          \n",
      "     very_recom              0                  308                  0                   20                  0          \n",
      "     spec_prior              0                  532                  0                   0                  3512        \n",
      "\n",
      "\n",
      "Class         recommend           's  recall is          0.0\n",
      "Class         priority           's  recall is          0.9029535864978903\n",
      "Class         not_recom           's  recall is          1.0\n",
      "Class         very_recom           's  recall is          0.06097560975609756\n",
      "Class         spec_prior           's  recall is          0.8684470820969338\n",
      "The micro-average recall is                0.5664752556701844\n",
      "\n",
      "\n",
      "Class         recommend           's  precision is          0\n",
      "Class         priority           's  precision is          0.8209718670076727\n",
      "Class         not_recom           's  precision is          1.0\n",
      "Class         very_recom           's  precision is          0.9090909090909091\n",
      "Class         spec_prior           's  precision is          0.8945491594498217\n",
      "The micro-average precision is                0.7249223871096807\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.07293460750309988\n",
      "The information gain for attribute      1        is        0.1964492804881155\n",
      "The information gain for attribute      2        is        0.005572591715219843\n",
      "The information gain for attribute      3        is        0.011886431475775838\n",
      "The information gain for attribute      4        is        0.019602025022871672\n",
      "The information gain for attribute      5        is        0.0043331270252002785\n",
      "The information gain for attribute      6        is        0.022232616894018342\n",
      "The information gain for attribute      7        is        0.9587749604699762\n",
      "distribution of the classes are\n",
      "{'recommend': 0.00015432098765432098, 'priority': 0.32916666666666666, 'not_recom': 0.3333333333333333, 'very_recom': 0.025308641975308643, 'spec_prior': 0.31203703703703706}\n",
      "\n",
      "\n",
      "number of the attributes are       8\n",
      "\n",
      "\n",
      "number of the instances are       12960\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is primary-tumor.csv\n",
      "The accracy is  0.6017699115044248\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|         A                   B                   C                   D                   E                   F                   G                   H                   J                   K                   L                   M                   N                   O                   P                   Q                   R                   S                   T                   U                   V          \n",
      "         A                   66                  2                   2                   2                   2                   0                   0                   0                   0                   4                   3                   0                   1                   0                   0                   1                   1                   0                   0                   0                   0          \n",
      "         B                   0                   20                  0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         C                   4                   1                   2                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0          \n",
      "         D                   2                   0                   0                   5                   0                   0                   0                   0                   0                   0                   0                   0                   4                   0                   0                   1                   0                   1                   0                   0                   1          \n",
      "         E                   4                   0                   0                   0                   11                  0                   0                   1                   0                   5                   3                   0                   3                   0                   0                   1                   8                   0                   0                   0                   3          \n",
      "         F                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         G                   0                   0                   0                   0                   3                   0                   1                   0                   0                   2                   5                   0                   1                   0                   0                   0                   1                   0                   1                   0                   0          \n",
      "         H                   0                   1                   0                   0                   1                   0                   0                   2                   0                   1                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         J                   0                   0                   0                   0                   0                   0                   0                   0                   2                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         K                   3                   0                   0                   0                   2                   0                   0                   0                   0                   13                  5                   0                   0                   0                   0                   0                   5                   0                   0                   0                   0          \n",
      "         L                   0                   0                   0                   0                   1                   0                   0                   0                   0                   2                   12                  0                   0                   0                   0                   0                   1                   0                   0                   0                   0          \n",
      "         M                   2                   0                   0                   1                   0                   1                   0                   0                   0                   0                   1                   2                   0                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         N                   4                   0                   0                   1                   3                   1                   0                   1                   0                   1                   1                   0                   8                   0                   0                   3                   1                   0                   0                   0                   0          \n",
      "         O                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0          \n",
      "         P                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0          \n",
      "         Q                   0                   0                   0                   0                   1                   0                   1                   0                   0                   1                   0                   0                   0                   0                   0                   7                   0                   0                   0                   0                   0          \n",
      "         R                   0                   0                   0                   0                   1                   0                   0                   0                   0                   1                   2                   0                   0                   0                   0                   0                   25                  0                   0                   0                   0          \n",
      "         S                   0                   0                   0                   1                   0                   0                   0                   0                   0                   3                   0                   0                   0                   0                   0                   0                   0                   2                   0                   0                   0          \n",
      "         T                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   2                   0                   0          \n",
      "         U                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   1                   0          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         V                   0                   0                   0                   2                   2                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   20         \n",
      "\n",
      "\n",
      "Class         A           's  recall is          0.7857142857142857\n",
      "Class         B           's  recall is          1.0\n",
      "Class         C           's  recall is          0.2222222222222222\n",
      "Class         D           's  recall is          0.35714285714285715\n",
      "Class         E           's  recall is          0.28205128205128205\n",
      "Class         F           's  recall is          1.0\n",
      "Class         G           's  recall is          0.07142857142857142\n",
      "Class         H           's  recall is          0.3333333333333333\n",
      "Class         J           's  recall is          1.0\n",
      "Class         K           's  recall is          0.4642857142857143\n",
      "Class         L           's  recall is          0.75\n",
      "Class         M           's  recall is          0.2857142857142857\n",
      "Class         N           's  recall is          0.3333333333333333\n",
      "Class         O           's  recall is          0.5\n",
      "Class         P           's  recall is          1.0\n",
      "Class         Q           's  recall is          0.7\n",
      "Class         R           's  recall is          0.8620689655172413\n",
      "Class         S           's  recall is          0.3333333333333333\n",
      "Class         T           's  recall is          1.0\n",
      "Class         U           's  recall is          1.0\n",
      "Class         V           's  recall is          0.8333333333333334\n",
      "The micro-average recall is                0.624474357971895\n",
      "\n",
      "\n",
      "Class         A           's  precision is          0.7764705882352941\n",
      "Class         B           's  precision is          0.8333333333333334\n",
      "Class         C           's  precision is          0.5\n",
      "Class         D           's  precision is          0.4166666666666667\n",
      "Class         E           's  precision is          0.39285714285714285\n",
      "Class         F           's  precision is          0.3333333333333333\n",
      "Class         G           's  precision is          0.5\n",
      "Class         H           's  precision is          0.5\n",
      "Class         J           's  precision is          1.0\n",
      "Class         K           's  precision is          0.38235294117647056\n",
      "Class         L           's  precision is          0.375\n",
      "Class         M           's  precision is          1.0\n",
      "Class         N           's  precision is          0.4444444444444444\n",
      "Class         O           's  precision is          1.0\n",
      "Class         P           's  precision is          1.0\n",
      "Class         Q           's  precision is          0.5\n",
      "Class         R           's  precision is          0.5952380952380952\n",
      "Class         S           's  precision is          0.6666666666666666\n",
      "Class         T           's  precision is          0.6666666666666666\n",
      "Class         U           's  precision is          1.0\n",
      "Class         V           's  precision is          0.8333333333333334\n",
      "The micro-average precision is                0.6531601529500689\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.1547421418870596\n",
      "The information gain for attribute      1        is        0.33536005150555503\n",
      "The information gain for attribute      2        is        1.0262234265467285\n",
      "The information gain for attribute      3        is        2.0947714990558133\n",
      "The information gain for attribute      4        is        0.21246189904816637\n",
      "The information gain for attribute      5        is        0.0203669388480483\n",
      "The information gain for attribute      6        is        0.10088123982399111\n",
      "The information gain for attribute      7        is        0.0678727757044233\n",
      "The information gain for attribute      8        is        0.22052193470670511\n",
      "The information gain for attribute      9        is        0.1997614363902529\n",
      "The information gain for attribute      10        is        0.06714460241010656\n",
      "The information gain for attribute      11        is        0.06025390884525317\n",
      "The information gain for attribute      12        is        0.29153013602249356\n",
      "The information gain for attribute      13        is        0.12715354518198252\n",
      "The information gain for attribute      14        is        0.2458886814337724\n",
      "The information gain for attribute      15        is        0.18425767171538476\n",
      "The information gain for attribute      16        is        0.17014811083887338\n",
      "distribution of the classes are\n",
      "{'A': 0.24778761061946902, 'B': 0.058997050147492625, 'C': 0.02654867256637168, 'D': 0.04129793510324484, 'E': 0.11504424778761062, 'F': 0.0029498525073746312, 'G': 0.04129793510324484, 'H': 0.017699115044247787, 'J': 0.0058997050147492625, 'K': 0.08259587020648967, 'L': 0.0471976401179941, 'M': 0.02064896755162242, 'N': 0.07079646017699115, 'O': 0.0058997050147492625, 'P': 0.0029498525073746312, 'Q': 0.029498525073746312, 'R': 0.0855457227138643, 'S': 0.017699115044247787, 'T': 0.0058997050147492625, 'U': 0.0029498525073746312, 'V': 0.07079646017699115}\n",
      "\n",
      "\n",
      "number of the attributes are       17\n",
      "\n",
      "\n",
      "number of the instances are       339\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model no smoothing\n",
    "\n",
    "#Main functionality\n",
    "#Check performace for each dataset given\n",
    "#Be care of the long output\n",
    "\n",
    "\n",
    "datas=[\"anneal.csv\",\"breast-cancer.csv\",\"car.csv\",\"cmc.csv\",\"hepatitis.csv\",\"hypothyroid.csv\",\"mushroom.csv\",\"nursery.csv\",\"primary-tumor.csv\"]\n",
    "for i in range(len(datas)):\n",
    "    data=preprocess(datas[i])\n",
    "    prior,post=train2(data)\n",
    "    pred=predict(data,prior,post)\n",
    "    print(\"The name of the dataset is \"+datas[i])\n",
    "    evaluate(data, pred)\n",
    "    info_gain(data,pred)\n",
    "    print(\"distribution of the classes are\")\n",
    "    print(prior)\n",
    "    print('\\n')\n",
    "    print(\"number of the attributes are      \",len(data[0])-1)\n",
    "    print('\\n')\n",
    "    print(\"number of the instances are      \",len(data))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print(\"**\"*50)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the dataset is anneal.csv\n",
      "The accracy is  0.9220489977728286\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|         3                   U                   1                   5                   2          \n",
      "         3                  618                  53                  1                   0                   12         \n",
      "         U                   2                   38                  0                   0                   0          \n",
      "         1                   1                   0                   7                   0                   0          \n",
      "         5                   0                   0                   0                   67                  0          \n",
      "         2                   1                   0                   0                   0                   98         \n",
      "\n",
      "\n",
      "Class         3           's  recall is          0.9035087719298246\n",
      "Class         U           's  recall is          0.95\n",
      "Class         1           's  recall is          0.875\n",
      "Class         5           's  recall is          1.0\n",
      "Class         2           's  recall is          0.98989898989899\n",
      "The micro-average recall is                0.9436815523657629\n",
      "\n",
      "\n",
      "Class         3           's  precision is          0.9935691318327974\n",
      "Class         U           's  precision is          0.4175824175824176\n",
      "Class         1           's  precision is          0.875\n",
      "Class         5           's  precision is          1.0\n",
      "Class         2           's  precision is          0.8909090909090909\n",
      "The micro-average precision is                0.8354121280648611\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.40908953764451006\n",
      "The information gain for attribute      1        is        0.0\n",
      "The information gain for attribute      2        is        0.3060515354289405\n",
      "The information gain for attribute      3        is        0.051344088764404106\n",
      "The information gain for attribute      4        is        0.29108220585994726\n",
      "The information gain for attribute      5        is        0.14711886228095605\n",
      "The information gain for attribute      6        is        0.2137228803159088\n",
      "The information gain for attribute      7        is        0.29223544065798446\n",
      "The information gain for attribute      8        is        0.1261663361036096\n",
      "The information gain for attribute      9        is        0.14107379163812883\n",
      "The information gain for attribute      10        is        0.032488406491841815\n",
      "The information gain for attribute      11        is        0.43517783626288575\n",
      "The information gain for attribute      12        is        0.03870173274881061\n",
      "The information gain for attribute      13        is        0.00043760652021185287\n",
      "The information gain for attribute      14        is        0.03935557414283708\n",
      "The information gain for attribute      15        is        0.021775078259213876\n",
      "The information gain for attribute      16        is        0.037997478813511565\n",
      "The information gain for attribute      17        is        0.03670308136440825\n",
      "The information gain for attribute      18        is        0.0\n",
      "The information gain for attribute      19        is        0.11722522630372034\n",
      "The information gain for attribute      20        is        0.029753745208638938\n",
      "The information gain for attribute      21        is        0.02704235332867677\n",
      "The information gain for attribute      22        is        0.0\n",
      "The information gain for attribute      23        is        0.015604780443500665\n",
      "The information gain for attribute      24        is        0.13718113252042574\n",
      "The information gain for attribute      25        is        0.0\n",
      "The information gain for attribute      26        is        0.0223970898516459\n",
      "The information gain for attribute      27        is        0.01824168402125048\n",
      "The information gain for attribute      28        is        0.0\n",
      "The information gain for attribute      29        is        0.0\n",
      "The information gain for attribute      30        is        0.0\n",
      "The information gain for attribute      31        is        0.04323960556514961\n",
      "The information gain for attribute      32        is        0.03303757117705719\n",
      "The information gain for attribute      33        is        0.01937886432831948\n",
      "The information gain for attribute      34        is        0.003958783545891853\n",
      "distribution of the classes are\n",
      "{'3': 0.7616926503340757, 'U': 0.044543429844097995, '1': 0.008908685968819599, '5': 0.07461024498886415, '2': 0.11024498886414254}\n",
      "\n",
      "\n",
      "number of the attributes are       35\n",
      "\n",
      "\n",
      "number of the instances are       898\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is breast-cancer.csv\n",
      "The accracy is  0.7482517482517482\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict| recurrence-events  no-recurrence-events\n",
      " recurrence-events           42                  43         \n",
      "no-recurrence-events         29                 172         \n",
      "\n",
      "\n",
      "Class         recurrence-events           's  recall is          0.49411764705882355\n",
      "Class         no-recurrence-events           's  recall is          0.8557213930348259\n",
      "The micro-average recall is                0.6749195200468248\n",
      "\n",
      "\n",
      "Class         recurrence-events           's  precision is          0.5915492957746479\n",
      "Class         no-recurrence-events           's  precision is          0.8\n",
      "The micro-average precision is                0.6957746478873239\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.010605956535614136\n",
      "The information gain for attribute      1        is        0.0020016149737116518\n",
      "The information gain for attribute      2        is        0.05717112532429669\n",
      "The information gain for attribute      3        is        0.06899508808988597\n",
      "The information gain for attribute      4        is        0.08012009687900967\n",
      "The information gain for attribute      5        is        0.07700985251661441\n",
      "The information gain for attribute      6        is        0.0024889884332655043\n",
      "The information gain for attribute      7        is        0.015066622054149992\n",
      "The information gain for attribute      8        is        0.025819023909141148\n",
      "distribution of the classes are\n",
      "{'recurrence-events': 0.2972027972027972, 'no-recurrence-events': 0.7027972027972028}\n",
      "\n",
      "\n",
      "number of the attributes are       9\n",
      "\n",
      "\n",
      "number of the instances are       286\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is car.csv\n",
      "The accracy is  0.8715277777777778\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|       unacc                acc                vgood                good        \n",
      "       unacc                1163                 45                  0                   2          \n",
      "        acc                  87                 287                  0                   10         \n",
      "       vgood                 0                   30                  35                  0          \n",
      "        good                 0                   46                  2                   21         \n",
      "\n",
      "\n",
      "Class         unacc           's  recall is          0.9611570247933884\n",
      "Class         acc           's  recall is          0.7473958333333334\n",
      "Class         vgood           's  recall is          0.5384615384615384\n",
      "Class         good           's  recall is          0.30434782608695654\n",
      "The micro-average recall is                0.6378405556688042\n",
      "\n",
      "\n",
      "Class         unacc           's  precision is          0.9304\n",
      "Class         acc           's  precision is          0.7034313725490197\n",
      "Class         vgood           's  precision is          0.9459459459459459\n",
      "Class         good           's  precision is          0.6363636363636364\n",
      "The micro-average precision is                0.8040352387146504\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.09644896916961399\n",
      "The information gain for attribute      1        is        0.07370394692148596\n",
      "The information gain for attribute      2        is        0.004485716626632108\n",
      "The information gain for attribute      3        is        0.2196629633399082\n",
      "The information gain for attribute      4        is        0.030008141247605424\n",
      "The information gain for attribute      5        is        0.26218435655426386\n",
      "distribution of the classes are\n",
      "{'unacc': 0.7002314814814815, 'acc': 0.2222222222222222, 'vgood': 0.03761574074074074, 'good': 0.03993055555555555}\n",
      "\n",
      "\n",
      "number of the attributes are       6\n",
      "\n",
      "\n",
      "number of the instances are       1728\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is cmc.csv\n",
      "The accracy is  0.5057705363204344\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|       No-use            Long-term           Short-term     \n",
      "       No-use               374                 135                 120         \n",
      "     Long-term               64                 190                  79         \n",
      "     Short-term             172                 158                 181         \n",
      "\n",
      "\n",
      "Class         No-use           's  recall is          0.5945945945945946\n",
      "Class         Long-term           's  recall is          0.5705705705705706\n",
      "Class         Short-term           's  recall is          0.3542074363992172\n",
      "The micro-average recall is                0.5064575338547941\n",
      "\n",
      "\n",
      "Class         No-use           's  precision is          0.6131147540983607\n",
      "Class         Long-term           's  precision is          0.39337474120082816\n",
      "Class         Short-term           's  precision is          0.4763157894736842\n",
      "The micro-average precision is                0.4942684282576244\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.07090633894894594\n",
      "The information gain for attribute      1        is        0.04013859922938412\n",
      "The information gain for attribute      2        is        0.10173991727554088\n",
      "The information gain for attribute      3        is        0.009820501434384843\n",
      "The information gain for attribute      4        is        0.002582332379721608\n",
      "The information gain for attribute      5        is        0.030474214560266555\n",
      "The information gain for attribute      6        is        0.032511460053806784\n",
      "The information gain for attribute      7        is        0.015786455595620197\n",
      "distribution of the classes are\n",
      "{'No-use': 0.4270196877121521, 'Long-term': 0.22606924643584522, 'Short-term': 0.3469110658520027}\n",
      "\n",
      "\n",
      "number of the attributes are       8\n",
      "\n",
      "\n",
      "number of the instances are       1473\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is hepatitis.csv\n",
      "The accracy is  0.832258064516129\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|        LIVE                DIE         \n",
      "        LIVE                106                  17         \n",
      "        DIE                  9                   23         \n",
      "\n",
      "\n",
      "Class         LIVE           's  recall is          0.8617886178861789\n",
      "Class         DIE           's  recall is          0.71875\n",
      "The micro-average recall is                0.7902693089430894\n",
      "\n",
      "\n",
      "Class         LIVE           's  precision is          0.9217391304347826\n",
      "Class         DIE           's  precision is          0.575\n",
      "The micro-average precision is                0.7483695652173913\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.03660746514280977\n",
      "The information gain for attribute      1        is        0.015265380561918285\n",
      "The information gain for attribute      2        is        0.014490701150154384\n",
      "The information gain for attribute      3        is        0.08645063847884216\n",
      "The information gain for attribute      4        is        0.08322845589007444\n",
      "The information gain for attribute      5        is        0.013806029835453981\n",
      "The information gain for attribute      6        is        0.0903522944652434\n",
      "The information gain for attribute      7        is        0.09049078626122975\n",
      "The information gain for attribute      8        is        0.058739302370822144\n",
      "The information gain for attribute      9        is        0.12938741279822152\n",
      "The information gain for attribute      10        is        0.15163520023638288\n",
      "The information gain for attribute      11        is        0.10012174391687245\n",
      "The information gain for attribute      12        is        0.08493296456638777\n",
      "distribution of the classes are\n",
      "{'LIVE': 0.7935483870967742, 'DIE': 0.2064516129032258}\n",
      "\n",
      "\n",
      "number of the attributes are       13\n",
      "\n",
      "\n",
      "number of the instances are       155\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the dataset is hypothyroid.csv\n",
      "The accracy is  0.9519443566234588\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|    hypothyroid           negative      \n",
      "    hypothyroid              0                  151         \n",
      "      negative               1                  3011        \n",
      "\n",
      "\n",
      "Class         hypothyroid           's  recall is          0.0\n",
      "Class         negative           's  recall is          0.999667994687915\n",
      "The micro-average recall is                0.4998339973439575\n",
      "\n",
      "\n",
      "Class         hypothyroid           's  precision is          0.0\n",
      "Class         negative           's  precision is          0.9522454142947502\n",
      "The micro-average precision is                0.4761227071473751\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.004628873031652547\n",
      "The information gain for attribute      1        is        0.0009139351160850073\n",
      "The information gain for attribute      2        is        0.0012382074503017315\n",
      "The information gain for attribute      3        is        0.00014844815831743796\n",
      "The information gain for attribute      4        is        0.0009985293906336068\n",
      "The information gain for attribute      5        is        0.0013683791752741592\n",
      "The information gain for attribute      6        is        0.0005423006444424394\n",
      "The information gain for attribute      7        is        0.0004350938464638965\n",
      "The information gain for attribute      8        is        0.0004888757691284829\n",
      "The information gain for attribute      9        is        0.0008983004044028076\n",
      "The information gain for attribute      10        is        4.463778824304043e-05\n",
      "The information gain for attribute      11        is        7.8684698479492e-05\n",
      "The information gain for attribute      12        is        0.009353710215580346\n",
      "The information gain for attribute      13        is        0.004075493419623766\n",
      "The information gain for attribute      14        is        0.005792553705846859\n",
      "The information gain for attribute      15        is        0.005768288201614624\n",
      "The information gain for attribute      16        is        0.005744031245602799\n",
      "The information gain for attribute      17        is        0.002580427555574416\n",
      "distribution of the classes are\n",
      "{'hypothyroid': 0.04773948782801138, 'negative': 0.9522605121719886}\n",
      "\n",
      "\n",
      "number of the attributes are       18\n",
      "\n",
      "\n",
      "number of the instances are       3163\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is mushroom.csv\n",
      "The accracy is  0.9588872476612507\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|         p                   e          \n",
      "         p                  3614                302         \n",
      "         e                   32                 4176        \n",
      "\n",
      "\n",
      "Class         p           's  recall is          0.9228804902962207\n",
      "Class         e           's  recall is          0.9923954372623575\n",
      "The micro-average recall is                0.9576379637792891\n",
      "\n",
      "\n",
      "Class         p           's  precision is          0.9912232583653319\n",
      "Class         e           's  precision is          0.9325591782045556\n",
      "The micro-average precision is                0.9618912182849437\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.04879670193537311\n",
      "The information gain for attribute      1        is        0.028590232773772817\n",
      "The information gain for attribute      2        is        0.03604928297620391\n",
      "The information gain for attribute      3        is        0.19237948576121966\n",
      "The information gain for attribute      4        is        0.9060749773839998\n",
      "The information gain for attribute      5        is        0.014165027250616302\n",
      "The information gain for attribute      6        is        0.10088318399657026\n",
      "The information gain for attribute      7        is        0.23015437514804615\n",
      "The information gain for attribute      8        is        0.41697752341613137\n",
      "The information gain for attribute      9        is        0.007516772569664321\n",
      "The information gain for attribute      10        is        0.4001378247172982\n",
      "The information gain for attribute      11        is        0.2847255992184845\n",
      "The information gain for attribute      12        is        0.2718944733927464\n",
      "The information gain for attribute      13        is        0.2538451734622399\n",
      "The information gain for attribute      14        is        0.24141556652756657\n",
      "The information gain for attribute      15        is        0.0\n",
      "The information gain for attribute      16        is        0.0238170161209168\n",
      "The information gain for attribute      17        is        0.03845266924309054\n",
      "The information gain for attribute      18        is        0.3180215107935376\n",
      "The information gain for attribute      19        is        0.4807049176849154\n",
      "The information gain for attribute      20        is        0.2019580190668524\n",
      "The information gain for attribute      21        is        0.1568336046050921\n",
      "distribution of the classes are\n",
      "{'p': 0.48202855736090594, 'e': 0.517971442639094}\n",
      "\n",
      "\n",
      "number of the attributes are       22\n",
      "\n",
      "\n",
      "number of the instances are       8124\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is nursery.csv\n",
      "The accracy is  0.9030092592592592\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|     recommend            priority           not_recom           very_recom          spec_prior     \n",
      "     recommend               0                   0                   0                   2                   0          \n",
      "      priority               0                  3852                 0                   0                  414         \n",
      "     not_recom               0                   0                  4320                 0                   0          \n",
      "     very_recom              0                  308                  0                   20                  0          \n",
      "     spec_prior              0                  533                  0                   0                  3511        \n",
      "\n",
      "\n",
      "Class         recommend           's  recall is          0.0\n",
      "Class         priority           's  recall is          0.9029535864978903\n",
      "Class         not_recom           's  recall is          1.0\n",
      "Class         very_recom           's  recall is          0.06097560975609756\n",
      "Class         spec_prior           's  recall is          0.8681998021760633\n",
      "The micro-average recall is                0.5664257996860103\n",
      "\n",
      "\n",
      "Class         recommend           's  precision is          0\n",
      "Class         priority           's  precision is          0.8207969316002557\n",
      "Class         not_recom           's  precision is          1.0\n",
      "Class         very_recom           's  precision is          0.9090909090909091\n",
      "Class         spec_prior           's  precision is          0.8945222929936306\n",
      "The micro-average precision is                0.7248820267369591\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.07293460750309988\n",
      "The information gain for attribute      1        is        0.1964492804881155\n",
      "The information gain for attribute      2        is        0.005572591715219843\n",
      "The information gain for attribute      3        is        0.011886431475775838\n",
      "The information gain for attribute      4        is        0.019602025022871672\n",
      "The information gain for attribute      5        is        0.0043331270252002785\n",
      "The information gain for attribute      6        is        0.022232616894018342\n",
      "The information gain for attribute      7        is        0.9587749604699762\n",
      "distribution of the classes are\n",
      "{'recommend': 0.00015432098765432098, 'priority': 0.32916666666666666, 'not_recom': 0.3333333333333333, 'very_recom': 0.025308641975308643, 'spec_prior': 0.31203703703703706}\n",
      "\n",
      "\n",
      "number of the attributes are       8\n",
      "\n",
      "\n",
      "number of the instances are       12960\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "The name of the dataset is primary-tumor.csv\n",
      "The accracy is  0.5545722713864307\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|         A                   B                   C                   D                   E                   F                   G                   H                   J                   K                   L                   M                   N                   O                   P                   Q                   R                   S                   T                   U                   V          \n",
      "         A                   66                  2                   1                   1                   2                   0                   0                   0                   1                   4                   2                   0                   3                   0                   0                   0                   2                   0                   0                   0                   0          \n",
      "         B                   0                   20                  0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         C                   5                   1                   1                   0                   0                   0                   0                   0                   0                   1                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         D                   4                   0                   0                   3                   0                   0                   0                   0                   0                   0                   0                   0                   5                   0                   0                   1                   0                   0                   0                   0                   1          \n",
      "         E                   3                   0                   0                   0                   12                  0                   0                   0                   0                   5                   3                   0                   4                   0                   0                   0                   8                   0                   1                   0                   3          \n",
      "         F                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         G                   1                   0                   0                   0                   4                   0                   0                   0                   0                   2                   5                   0                   1                   0                   0                   0                   1                   0                   0                   0                   0          \n",
      "         H                   0                   1                   0                   0                   2                   0                   0                   1                   0                   1                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         J                   0                   1                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         K                   4                   0                   0                   0                   3                   0                   0                   0                   0                   12                  4                   0                   0                   0                   0                   0                   5                   0                   0                   0                   0          \n",
      "         L                   0                   0                   0                   0                   0                   0                   0                   0                   0                   2                   12                  0                   0                   0                   0                   0                   1                   1                   0                   0                   0          \n",
      "         M                   2                   0                   0                   1                   0                   0                   1                   0                   0                   0                   1                   0                   1                   0                   0                   0                   1                   0                   0                   0                   0          \n",
      "         N                   4                   0                   0                   1                   3                   0                   0                   0                   0                   2                   1                   0                   12                  0                   0                   0                   1                   0                   0                   0                   0          \n",
      "         O                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0          \n",
      "         P                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   0          \n",
      "         Q                   0                   1                   0                   0                   1                   0                   0                   0                   0                   2                   0                   0                   3                   0                   0                   3                   0                   0                   0                   0                   0          \n",
      "         R                   0                   0                   0                   0                   1                   0                   0                   0                   0                   1                   2                   0                   0                   0                   0                   0                   25                  0                   0                   0                   0          \n",
      "         S                   0                   0                   0                   0                   0                   0                   0                   0                   0                   3                   1                   0                   1                   0                   0                   0                   1                   0                   0                   0                   0          \n",
      "         T                   0                   0                   0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0          \n",
      "         U                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0          \n",
      "         V                   0                   0                   1                   2                   0                   0                   0                   0                   0                   1                   0                   0                   0                   0                   0                   0                   1                   0                   0                   0                   19         \n",
      "\n",
      "\n",
      "Class         A           's  recall is          0.7857142857142857\n",
      "Class         B           's  recall is          1.0\n",
      "Class         C           's  recall is          0.1111111111111111\n",
      "Class         D           's  recall is          0.21428571428571427\n",
      "Class         E           's  recall is          0.3076923076923077\n",
      "Class         F           's  recall is          0.0\n",
      "Class         G           's  recall is          0.0\n",
      "Class         H           's  recall is          0.16666666666666666\n",
      "Class         J           's  recall is          0.5\n",
      "Class         K           's  recall is          0.42857142857142855\n",
      "Class         L           's  recall is          0.75\n",
      "Class         M           's  recall is          0.0\n",
      "Class         N           's  recall is          0.5\n",
      "Class         O           's  recall is          0.5\n",
      "Class         P           's  recall is          0.0\n",
      "Class         Q           's  recall is          0.3\n",
      "Class         R           's  recall is          0.8620689655172413\n",
      "Class         S           's  recall is          0.0\n",
      "Class         T           's  recall is          0.0\n",
      "Class         U           's  recall is          0.0\n",
      "Class         V           's  recall is          0.7916666666666666\n",
      "The micro-average recall is                0.343703673629782\n",
      "\n",
      "\n",
      "Class         A           's  precision is          0.7415730337078652\n",
      "Class         B           's  precision is          0.7692307692307693\n",
      "Class         C           's  precision is          0.3333333333333333\n",
      "Class         D           's  precision is          0.375\n",
      "Class         E           's  precision is          0.41379310344827586\n",
      "Class         F           's  precision is          0\n",
      "Class         G           's  precision is          0.0\n",
      "Class         H           's  precision is          1.0\n",
      "Class         J           's  precision is          0.5\n",
      "Class         K           's  precision is          0.32432432432432434\n",
      "Class         L           's  precision is          0.3870967741935484\n",
      "Class         M           's  precision is          0\n",
      "Class         N           's  precision is          0.35294117647058826\n",
      "Class         O           's  precision is          1.0\n",
      "Class         P           's  precision is          0\n",
      "Class         Q           's  precision is          0.75\n",
      "Class         R           's  precision is          0.5434782608695652\n",
      "Class         S           's  precision is          0.0\n",
      "Class         T           's  precision is          0.0\n",
      "Class         U           's  precision is          0\n",
      "Class         V           's  precision is          0.8260869565217391\n",
      "The micro-average precision is                0.3960408443857147\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.1547421418870596\n",
      "The information gain for attribute      1        is        0.33536005150555503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The information gain for attribute      2        is        1.0262234265467285\n",
      "The information gain for attribute      3        is        2.0947714990558133\n",
      "The information gain for attribute      4        is        0.21246189904816637\n",
      "The information gain for attribute      5        is        0.0203669388480483\n",
      "The information gain for attribute      6        is        0.10088123982399111\n",
      "The information gain for attribute      7        is        0.0678727757044233\n",
      "The information gain for attribute      8        is        0.22052193470670511\n",
      "The information gain for attribute      9        is        0.1997614363902529\n",
      "The information gain for attribute      10        is        0.06714460241010656\n",
      "The information gain for attribute      11        is        0.06025390884525317\n",
      "The information gain for attribute      12        is        0.29153013602249356\n",
      "The information gain for attribute      13        is        0.12715354518198252\n",
      "The information gain for attribute      14        is        0.2458886814337724\n",
      "The information gain for attribute      15        is        0.18425767171538476\n",
      "The information gain for attribute      16        is        0.17014811083887338\n",
      "distribution of the classes are\n",
      "{'A': 0.24778761061946902, 'B': 0.058997050147492625, 'C': 0.02654867256637168, 'D': 0.04129793510324484, 'E': 0.11504424778761062, 'F': 0.0029498525073746312, 'G': 0.04129793510324484, 'H': 0.017699115044247787, 'J': 0.0058997050147492625, 'K': 0.08259587020648967, 'L': 0.0471976401179941, 'M': 0.02064896755162242, 'N': 0.07079646017699115, 'O': 0.0058997050147492625, 'P': 0.0029498525073746312, 'Q': 0.029498525073746312, 'R': 0.0855457227138643, 'S': 0.017699115044247787, 'T': 0.0058997050147492625, 'U': 0.0029498525073746312, 'V': 0.07079646017699115}\n",
      "\n",
      "\n",
      "number of the attributes are       17\n",
      "\n",
      "\n",
      "number of the instances are       339\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model with lapace smoothing\n",
    "\n",
    "#Main functionality\n",
    "#Check performace for each dataset given\n",
    "#Be care of the long output\n",
    "\n",
    "\n",
    "datas=[\"anneal.csv\",\"breast-cancer.csv\",\"car.csv\",\"cmc.csv\",\"hepatitis.csv\",\"hypothyroid.csv\",\"mushroom.csv\",\"nursery.csv\",\"primary-tumor.csv\"]\n",
    "for i in range(len(datas)):\n",
    "    data=preprocess(datas[i])\n",
    "    prior,post=train(data)\n",
    "    pred=predict(data,prior,post)\n",
    "    print(\"The name of the dataset is \"+datas[i])\n",
    "    evaluate(data, pred)\n",
    "    info_gain(data,pred)\n",
    "    print(\"distribution of the classes are\")\n",
    "    print(prior)\n",
    "    print('\\n')\n",
    "    print(\"number of the attributes are      \",len(data[0])-1)\n",
    "    print('\\n')\n",
    "    print(\"number of the instances are      \",len(data))\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print(\"**\"*50)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (you may respond in a cell or cells below):\n",
    "\n",
    "1. The Naive Bayes classifiers can be seen to vary, in terms of their effectiveness on the given datasets (e.g. in terms of Accuracy). Consider the Information Gain of each attribute, relative to the class distribution  does this help to explain the classifiers behaviour? Identify any results that are particularly surprising, and explain why they occur.\n",
    "2. The Information Gain can be seen as a kind of correlation coefficient between a pair of attributes: when the gain is low, the attribute values are uncorrelated; when the gain is high, the attribute values are correlated. In supervised ML, we typically calculate the Infomation Gain between a single attribute and the class, but it can be calculated for any pair of attributes. Using the pair-wise IG as a proxy for attribute interdependence, in which cases are our NB assumptions violated? Describe any evidence (or indeed, lack of evidence) that this is has some effect on the effectiveness of the NB classifier.\n",
    "3. Since we have gone to all of the effort of calculating Infomation Gain, we might as well use that as a criterion for building a Decision Stump (1-R classifier). How does the effectiveness of this classifier compare to Naive Bayes? Identify one or more cases where the effectiveness is notably different, and explain why.\n",
    "4. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a holdout or crossvalidation evaluation strategy. How does your estimate of effectiveness change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "5. Implement one of the advanced smoothing regimes (add-k, Good-Turing). Does changing the smoothing regime (or indeed, not smoothing at all) affect the effectiveness of the Naive Bayes classifier? Explain why, or why not.\n",
    "6. Naive Bayes is said to elegantly handle missing attribute values. For the datasets with missing values, is there any evidence that the performance is different on the instances with missing values, compared to the instances where all of the values are present? Does it matter which, or how many values are missing? Would a imputation strategy have any effect on this?\n",
    "\n",
    "Don't forget that groups of 1 student should respond to question (1), and one other question of your choosing. Groups of 2 students should respond to question (1) and question (2), and two other questions of your choosing. Your responses should be about 150-250 words each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 1\n",
    "\n",
    "1. The Naive Bayes classifiers can be seen to vary, in terms of their effectiveness on the given datasets (e.g. in terms of Accuracy). Consider the Information Gain of each attribute, relative to the class distribution  does this help to explain the classifiers behaviour? Identify any results that are particularly surprising, and explain why they occur.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anneal.csv\n",
      "The Accuracy is                  0.9220489977728286\n",
      "\n",
      "\n",
      "breast-cancer.csv\n",
      "The Accuracy is                  0.7482517482517482\n",
      "\n",
      "\n",
      "car.csv\n",
      "The Accuracy is                  0.8715277777777778\n",
      "\n",
      "\n",
      "cmc.csv\n",
      "The Accuracy is                  0.5057705363204344\n",
      "\n",
      "\n",
      "hepatitis.csv\n",
      "The Accuracy is                  0.832258064516129\n",
      "\n",
      "\n",
      "hypothyroid.csv\n",
      "The Accuracy is                  0.9519443566234588\n",
      "\n",
      "\n",
      "mushroom.csv\n",
      "The Accuracy is                  0.9588872476612507\n",
      "\n",
      "\n",
      "nursery.csv\n",
      "The Accuracy is                  0.9030092592592592\n",
      "\n",
      "\n",
      "primary-tumor.csv\n",
      "The Accuracy is                  0.5545722713864307\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#the accracy for each dataset\n",
    "#use the result of the model with laplace smoothing\n",
    "\n",
    "datas=[\"anneal.csv\",\"breast-cancer.csv\",\"car.csv\",\"cmc.csv\",\"hepatitis.csv\",\"hypothyroid.csv\",\"mushroom.csv\",\"nursery.csv\",\"primary-tumor.csv\"]\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    data=preprocess(datas[i])\n",
    "    a,b=train(data)\n",
    "    pred=predict(data,a,b)\n",
    "    print(datas[i])\n",
    "    print(\"The Accuracy is                 \", get_accuracy(data, pred)/len(data))\n",
    "    \n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The \n",
    "following factors reagrds the dataset are considered to positively affect the classifier to make it perform better and get trained better.\n",
    "\n",
    "1. A decently large size of instances, attributes and classes.\n",
    "\n",
    "\n",
    "In this way, the classifier will take more cirsumstances into training to reduce bias.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. (As) Evenly (as possible) distributed classes and attributes\n",
    "\n",
    "\n",
    "The number of each class and attribute value should be better more close to each other. Information gain perfers highly braching data. Evenly distributed can also reduce bias and gain a general perspective on the reality.\n",
    "\n",
    "Next, analyse dataset \"hypothyroid.csv\", \"mushroom.csv\" and \"cmc.csv\" as examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothyroid.csv\n",
      "The Accuracy is                  0.9519443566234588 \n",
      "\n",
      "The accracy is  0.9519443566234588\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|    hypothyroid           negative      \n",
      "    hypothyroid              0                  151         \n",
      "      negative               1                  3011        \n",
      "\n",
      "\n",
      "Class         hypothyroid           's  recall is          0.0\n",
      "Class         negative           's  recall is          0.999667994687915\n",
      "The micro-average recall is                0.4998339973439575\n",
      "\n",
      "\n",
      "Class         hypothyroid           's  precision is          0.0\n",
      "Class         negative           's  precision is          0.9522454142947502\n",
      "The micro-average precision is                0.4761227071473751\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.004628873031652547\n",
      "The information gain for attribute      1        is        0.0009139351160850073\n",
      "The information gain for attribute      2        is        0.0012382074503017315\n",
      "The information gain for attribute      3        is        0.00014844815831743796\n",
      "The information gain for attribute      4        is        0.0009985293906336068\n",
      "The information gain for attribute      5        is        0.0013683791752741592\n",
      "The information gain for attribute      6        is        0.0005423006444424394\n",
      "The information gain for attribute      7        is        0.0004350938464638965\n",
      "The information gain for attribute      8        is        0.0004888757691284829\n",
      "The information gain for attribute      9        is        0.0008983004044028076\n",
      "The information gain for attribute      10        is        4.463778824304043e-05\n",
      "The information gain for attribute      11        is        7.8684698479492e-05\n",
      "The information gain for attribute      12        is        0.009353710215580346\n",
      "The information gain for attribute      13        is        0.004075493419623766\n",
      "The information gain for attribute      14        is        0.005792553705846859\n",
      "The information gain for attribute      15        is        0.005768288201614624\n",
      "The information gain for attribute      16        is        0.005744031245602799\n",
      "The information gain for attribute      17        is        0.002580427555574416\n",
      "distribution of the classes are\n",
      "{'hypothyroid': 0.04773948782801138, 'negative': 0.9522605121719886}\n",
      "\n",
      "\n",
      "number of the attributes are       18\n",
      "\n",
      "\n",
      "number of the instances are       3163\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datas=\"hypothyroid.csv\"\n",
    "data=preprocess(datas)\n",
    "prior,post=train(data)\n",
    "pred=predict(data,prior,post)\n",
    "print(datas)\n",
    "print(\"The Accuracy is                 \", get_accuracy(data, pred)/len(data),'\\n')\n",
    "evaluate(data, pred)\n",
    "info_gain(data,pred)\n",
    "print(\"distribution of the classes are\")\n",
    "print(prior)\n",
    "print('\\n')\n",
    "print(\"number of the attributes are      \",len(data[0])-1)\n",
    "print('\\n')\n",
    "print(\"number of the instances are      \",len(data))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\"hypothyroid.csv\" shows surprising result. \n",
    "The ratio of the two classes are 0.95:0.4. The majority of the classes are \"negative\", which has a huge impact on the prior and posterior probaility and the prediction. The precision and recall for class \"hypothyroid\" are both 0 and low information gain for every attribute, which means the classifier did not learn enough instance with class \"hypothyroid\". High accuracy does not mean classifier is good. In fact, not evenly distributed classes affect the classifier badly. In this case, the classifier cannot handle instances that actually under class \"hypothyroid\".\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mushroom.csv\n",
      "The Accuracy is                  0.9588872476612507 \n",
      "\n",
      "The accracy is  0.9588872476612507\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|         p                   e          \n",
      "         p                  3614                302         \n",
      "         e                   32                 4176        \n",
      "\n",
      "\n",
      "Class         p           's  recall is          0.9228804902962207\n",
      "Class         e           's  recall is          0.9923954372623575\n",
      "The micro-average recall is                0.9576379637792891\n",
      "\n",
      "\n",
      "Class         p           's  precision is          0.9912232583653319\n",
      "Class         e           's  precision is          0.9325591782045556\n",
      "The micro-average precision is                0.9618912182849437\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.04879670193537311\n",
      "The information gain for attribute      1        is        0.028590232773772817\n",
      "The information gain for attribute      2        is        0.03604928297620391\n",
      "The information gain for attribute      3        is        0.19237948576121966\n",
      "The information gain for attribute      4        is        0.9060749773839998\n",
      "The information gain for attribute      5        is        0.014165027250616302\n",
      "The information gain for attribute      6        is        0.10088318399657026\n",
      "The information gain for attribute      7        is        0.23015437514804615\n",
      "The information gain for attribute      8        is        0.41697752341613137\n",
      "The information gain for attribute      9        is        0.007516772569664321\n",
      "The information gain for attribute      10        is        0.4001378247172982\n",
      "The information gain for attribute      11        is        0.2847255992184845\n",
      "The information gain for attribute      12        is        0.2718944733927464\n",
      "The information gain for attribute      13        is        0.2538451734622399\n",
      "The information gain for attribute      14        is        0.24141556652756657\n",
      "The information gain for attribute      15        is        0.0\n",
      "The information gain for attribute      16        is        0.0238170161209168\n",
      "The information gain for attribute      17        is        0.03845266924309054\n",
      "The information gain for attribute      18        is        0.3180215107935376\n",
      "The information gain for attribute      19        is        0.4807049176849154\n",
      "The information gain for attribute      20        is        0.2019580190668524\n",
      "The information gain for attribute      21        is        0.1568336046050921\n",
      "distribution of the classes are\n",
      "{'p': 0.48202855736090594, 'e': 0.517971442639094}\n",
      "\n",
      "\n",
      "number of the attributes are       22\n",
      "\n",
      "\n",
      "number of the instances are       8124\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datas2=\"mushroom.csv\"\n",
    "data2=preprocess(datas2)\n",
    "prior2,post2=train(data2)\n",
    "pred2=predict(data2,prior2,post2)\n",
    "print(datas2)\n",
    "print(\"The Accuracy is                 \", get_accuracy(data2, pred2)/len(data2),'\\n')\n",
    "evaluate(data2, pred2)\n",
    "info_gain(data2,pred2)\n",
    "print(\"distribution of the classes are\")\n",
    "print(prior2)\n",
    "print('\\n')\n",
    "print(\"number of the attributes are      \",len(data2[0])-1)\n",
    "print('\\n')\n",
    "print(\"number of the instances are      \",len(data2))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\"mushroom.csv\"\n",
    "One of the best datasets and best result in the project for following reasons:\n",
    "1. Evenly distributed classes and attributes. \n",
    "2. High Information gain for particular attributes, high precision and recall for both classes. \n",
    "3. Decent number of attributes and instance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmc.csv\n",
      "The Accuracy is                  0.5057705363204344 \n",
      "\n",
      "The accracy is  0.5057705363204344\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "\n",
      "|Actual\\Predict|       No-use            Long-term           Short-term     \n",
      "       No-use               374                 135                 120         \n",
      "     Long-term               64                 190                  79         \n",
      "     Short-term             172                 158                 181         \n",
      "\n",
      "\n",
      "Class         No-use           's  recall is          0.5945945945945946\n",
      "Class         Long-term           's  recall is          0.5705705705705706\n",
      "Class         Short-term           's  recall is          0.3542074363992172\n",
      "The micro-average recall is                0.5064575338547941\n",
      "\n",
      "\n",
      "Class         No-use           's  precision is          0.6131147540983607\n",
      "Class         Long-term           's  precision is          0.39337474120082816\n",
      "Class         Short-term           's  precision is          0.4763157894736842\n",
      "The micro-average precision is                0.4942684282576244\n",
      "\n",
      "\n",
      "The information gain for attribute      0        is        0.07090633894894594\n",
      "The information gain for attribute      1        is        0.04013859922938412\n",
      "The information gain for attribute      2        is        0.10173991727554088\n",
      "The information gain for attribute      3        is        0.009820501434384843\n",
      "The information gain for attribute      4        is        0.002582332379721608\n",
      "The information gain for attribute      5        is        0.030474214560266555\n",
      "The information gain for attribute      6        is        0.032511460053806784\n",
      "The information gain for attribute      7        is        0.015786455595620197\n",
      "distribution of the classes are\n",
      "{'No-use': 0.4270196877121521, 'Long-term': 0.22606924643584522, 'Short-term': 0.3469110658520027}\n",
      "\n",
      "\n",
      "number of the attributes are       8\n",
      "\n",
      "\n",
      "number of the instances are       1473\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datas23=\"cmc.csv\"\n",
    "data23=preprocess(datas23)\n",
    "prior23,post23=train(data23)\n",
    "pred23=predict(data23,prior23,post23)\n",
    "print(datas23)\n",
    "print(\"The Accuracy is                 \", get_accuracy(data23, pred23)/len(data23),'\\n')\n",
    "evaluate(data23, pred23)\n",
    "info_gain(data23,pred23)\n",
    "print(\"distribution of the classes are\")\n",
    "print(prior23)\n",
    "print('\\n')\n",
    "print(\"number of the attributes are      \",len(data23[0])-1)\n",
    "print('\\n')\n",
    "print(\"number of the instances are      \",len(data23))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"cmc.csv\"\n",
    "Result not so good for fowlloing reason:\n",
    "1. realtive low numbers of attributes.\n",
    "2. small data size\n",
    "3. low information gain means the attributes branching poorly so not much useful information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "Implement one of the advanced smoothing regimes (add-k, Good-Turing). Does changing the smoothing regime (or indeed, not smoothing at all) affect the effectiveness of the Naive Bayes classifier? Explain why, or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I used Laplace add-k (k=1) smoothing to handle data. The effectiveness of changing the smoothing regime in this projectmay not be that obivious or even result in a lower raccuracy because we are treating the train data as the test data. \n",
    "\n",
    "Use datasets accuracy as an exmaple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anneal.csv\n",
      "No Smoothing accuracy is                  0.9910913140311804\n",
      "\n",
      "\n",
      "Add-k Smoothing accuracy is                  0.9220489977728286\n",
      "\n",
      "\n",
      "breast-cancer.csv\n",
      "No Smoothing accuracy is                  0.7587412587412588\n",
      "\n",
      "\n",
      "Add-k Smoothing accuracy is                  0.7482517482517482\n",
      "\n",
      "\n",
      "car.csv\n",
      "No Smoothing accuracy is                  0.8738425925925926\n",
      "\n",
      "\n",
      "Add-k Smoothing accuracy is                  0.8715277777777778\n",
      "\n",
      "\n",
      "cmc.csv\n",
      "No Smoothing accuracy is                  0.5057705363204344\n",
      "\n",
      "\n",
      "Add-k Smoothing accuracy is                  0.5057705363204344\n",
      "\n",
      "\n",
      "hepatitis.csv\n",
      "No Smoothing accuracy is                  0.8387096774193549\n",
      "\n",
      "\n",
      "Add-k Smoothing accuracy is                  0.832258064516129\n",
      "\n",
      "\n",
      "hypothyroid.csv\n",
      "No Smoothing accuracy is                  0.9522605121719886\n",
      "\n",
      "\n",
      "Add-k Smoothing accuracy is                  0.9519443566234588\n",
      "\n",
      "\n",
      "mushroom.csv\n",
      "No Smoothing accuracy is                  0.9958148695224027\n",
      "\n",
      "\n",
      "Add-k Smoothing accuracy is                  0.9588872476612507\n",
      "\n",
      "\n",
      "nursery.csv\n",
      "No Smoothing accuracy is                  0.9030864197530865\n",
      "\n",
      "\n",
      "Add-k Smoothing accuracy is                  0.9030092592592592\n",
      "\n",
      "\n",
      "primary-tumor.csv\n",
      "No Smoothing accuracy is                  0.6017699115044248\n",
      "\n",
      "\n",
      "Add-k Smoothing accuracy is                  0.5545722713864307\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accracy of models without smoothing and with smoothing\n",
    "\n",
    "datas=[\"anneal.csv\",\"breast-cancer.csv\",\"car.csv\",\"cmc.csv\",\"hepatitis.csv\",\"hypothyroid.csv\",\"mushroom.csv\",\"nursery.csv\",\"primary-tumor.csv\"]\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    data=preprocess(datas[i])\n",
    "    a,b=train2(data)\n",
    "    c,d=train(data)\n",
    "    pred=predict(data,a,b)\n",
    "    pred2=predict(data,c,d)\n",
    "    print(datas[i])\n",
    "    print(\"No Smoothing accuracy is                 \", get_accuracy(data, pred)/len(data))\n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"Add-k Smoothing accuracy is                 \", get_accuracy(data, pred2)/len(data))\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the above results shows. In this project, the accuracy of model without smoothing is higher than model with smoothing for EVERY DATASET!!!\n",
    "\n",
    "\n",
    "Smoothing is to adjust zeros that in our data to some small number. The whole reason is that we generally assume there is nothing \"impossible\" or \"abusolutely zero probability\" unless there is a particular assumption. e.g. A fish can fly, we have flying fish in reality. It may not in our training data, but it exist in reality. So rather than treat the probaility of fish can fly to 0, we rather assign some reasonably small value to it.\n",
    "\n",
    "However, in this project, we use trained data as test data. This decision adjusted our assumptions to \"we assume something is impossible\", because we don't need to consider the case that the classifier hasn't learned since it has already learned \"everything\". The purpose of smoothing is to help classifier deal with circumstances that we rarely seen to prevent potienal bias and mistakes. Since we use trained data to test in this project, smoothing does not prevent potienal mistakes but add mistakes to the classifier.\n",
    "\n",
    "\n",
    "In reality, rather than classifier with no smoothing method, however, it is believed that smoothing will help build a better classifier when dealing with unseen instances.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
